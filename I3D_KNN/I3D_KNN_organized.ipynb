{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b8cffc",
   "metadata": {},
   "source": [
    "## 1. üì¶ Import Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, deep learning, and anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5476adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# FAISS with safe fallback to CPU if GPU module missing\n",
    "try:\n",
    "    import faiss\n",
    "except ImportError:\n",
    "    print(\"Installing faiss-gpu...\")\n",
    "    os.system(\"pip uninstall -y faiss-cpu\")  # Remove CPU version to prevent conflicts\n",
    "    os.system(\"pip install faiss-gpu -q\")\n",
    "    import faiss\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db3816",
   "metadata": {},
   "source": [
    "## 2. ‚öôÔ∏è Configuration & Setup\n",
    "\n",
    "Configure hyperparameters, paths, and environment setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL & EXTRACTION HYPERPARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "IMG_SIZE = 224              # I3D input size\n",
    "SEQ_LEN = 16                # Frames per clip (I3D requirement)\n",
    "BATCH_SIZE = 4              # Batch size for I3D extraction\n",
    "K_NEIGHBORS = 5             # Number of neighbors for KNN\n",
    "NUM_WORKERS = 4             # Parallel workers for image loading\n",
    "\n",
    "# =============================================================================\n",
    "# CACHE & STORAGE CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "CACHE_DIR = \"/kaggle/working/cache\"\n",
    "FEATURE_CACHE = os.path.join(CACHE_DIR, \"features\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET PATHS\n",
    "# =============================================================================\n",
    "\n",
    "DATA_ROOT = \"/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset\"\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, \"training_videos\")\n",
    "TEST_DIR = os.path.join(DATA_ROOT, \"testing_videos\")\n",
    "OUTPUT_CSV = \"avenue_scores.csv\"\n",
    "\n",
    "# =============================================================================\n",
    "# REPRODUCIBILITY & DEVICE\n",
    "# =============================================================================\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create cache directory\n",
    "os.makedirs(FEATURE_CACHE, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Device: {device}\")\n",
    "print(f\"‚úì Cache: {FEATURE_CACHE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f620722",
   "metadata": {},
   "source": [
    "## 3. üñºÔ∏è Vectorized Image Loading\n",
    "\n",
    "Efficient parallel image loading with vectorized normalization using ImageNet statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NORMALIZATION CONSTANTS (ImageNet)\n",
    "# =============================================================================\n",
    "\n",
    "MEAN = np.array([0.45, 0.45, 0.45], dtype=np.float32).reshape(1, 1, 1, 3)\n",
    "STD = np.array([0.225, 0.225, 0.225], dtype=np.float32).reshape(1, 1, 1, 3)\n",
    "\n",
    "\n",
    "def load_single_image_raw(path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load a single image without normalization (uint8).\n",
    "    \n",
    "    Args:\n",
    "        path: Path to image file\n",
    "        \n",
    "    Returns:\n",
    "        img: (H, W, C) uint8 numpy array\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "    # Convert BGR to RGB and resize\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_images_vectorized(paths: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    VECTORIZED: Load multiple images in parallel with efficient normalization.\n",
    "    \n",
    "    Uses ThreadPoolExecutor for parallel I/O and numpy broadcasting for\n",
    "    fast vectorized normalization.\n",
    "    \n",
    "    Args:\n",
    "        paths: List of image file paths\n",
    "        \n",
    "    Returns:\n",
    "        batch: (N, H, W, C) float32 normalized numpy array\n",
    "    \"\"\"\n",
    "    # Parallel I/O loading\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        images = list(executor.map(load_single_image_raw, paths))\n",
    "    \n",
    "    # VECTORIZED: Stack and normalize in one operation\n",
    "    batch = np.stack(images, axis=0).astype(np.float32)  # (N, H, W, C)\n",
    "    batch = (batch / 255.0 - MEAN) / STD  # Vectorized normalization\n",
    "    \n",
    "    return batch\n",
    "\n",
    "\n",
    "def load_clip_vectorized(frame_paths: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load a video clip with vectorized normalization.\n",
    "    \n",
    "    Args:\n",
    "        frame_paths: List of frame image paths\n",
    "        \n",
    "    Returns:\n",
    "        clip: (T, H, W, C) float32 normalized numpy array\n",
    "    \"\"\"\n",
    "    return load_images_vectorized(frame_paths)\n",
    "\n",
    "\n",
    "def get_frame_num(path: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract frame number from filename.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to frame image\n",
    "        \n",
    "    Returns:\n",
    "        frame_num: Integer frame number\n",
    "    \"\"\"\n",
    "    name = os.path.basename(path)\n",
    "    digits = ''.join(filter(str.isdigit, os.path.splitext(name)[0]))\n",
    "    return int(digits) if digits else 0\n",
    "\n",
    "\n",
    "print(\"‚úì Image loading functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d32005",
   "metadata": {},
   "source": [
    "## 4. üß† I3D Feature Extractor\n",
    "\n",
    "I3D (Inflated 3D ConvNet) extracts 2048-dimensional features from video clips using a pre-trained ResNet-50 backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class I3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Singleton I3D model wrapper (loads only once).\n",
    "    \n",
    "    Uses Facebook's PyTorchVideo i3d_r50 (ResNet-50 backbone).\n",
    "    Pre-trained on Kinetics dataset for action recognition.\n",
    "    \n",
    "    Architecture:\n",
    "        Input:  (B, C=3, T=16, H=224, W=224)\n",
    "        Output: (B, 2048) feature vectors\n",
    "    \"\"\"\n",
    "    _instance = None  # Singleton instance\n",
    "    \n",
    "    def __new__(cls):\n",
    "        # Return existing instance if available\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super().__new__(cls)\n",
    "            cls._instance._initialized = False\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Skip re-initialization if already done\n",
    "        if self._initialized:\n",
    "            return\n",
    "        super().__init__()\n",
    "        \n",
    "        print(\"Loading I3D model from PyTorchVideo...\")\n",
    "        \n",
    "        # Load pretrained I3D ResNet-50\n",
    "        self.model = torch.hub.load(\n",
    "            'facebookresearch/pytorchvideo',\n",
    "            'i3d_r50',\n",
    "            pretrained=True\n",
    "        )\n",
    "        \n",
    "        # Remove classification head, keep features only\n",
    "        self.model.blocks[-1].proj = nn.Identity()\n",
    "        \n",
    "        # Freeze all parameters (inference only)\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        self.eval()\n",
    "        self._initialized = True\n",
    "        print(\"‚úì I3D model loaded\")\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extract features from video clips.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (B, C, T, H, W)\n",
    "            \n",
    "        Returns:\n",
    "            features: Output tensor of shape (B, 2048)\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "print(\"‚úì I3D class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead87c34",
   "metadata": {},
   "source": [
    "## 5. üìä Feature Extraction Functions\n",
    "\n",
    "Extract and normalize I3D features from training and test videos with caching for faster re-runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_vectorized(data_dir: str, name: str, stride: int = 1) -> Tuple:\n",
    "    \"\"\"\n",
    "    VECTORIZED feature extraction with caching and normalization.\n",
    "    \n",
    "    Steps:\n",
    "        1. Create video clips from frames\n",
    "        2. Extract I3D features for each clip\n",
    "        3. Compute normalization statistics (mean, std)\n",
    "        4. Normalize all features\n",
    "        5. Cache results to disk\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing video folders\n",
    "        name: Name for caching (e.g., \"train\")\n",
    "        stride: Stride between consecutive clips\n",
    "        \n",
    "    Returns:\n",
    "        features: (N, 2048) normalized tensor\n",
    "        clips: List of clip metadata\n",
    "        videos: Dict of video metadata\n",
    "        stats: Normalization statistics {mean, std}\n",
    "    \"\"\"\n",
    "    cache_file = os.path.join(FEATURE_CACHE, f\"{name}_v2_s{stride}.pt\")\n",
    "    \n",
    "    # Check cache first\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"[CACHE HIT] Loading {name}\")\n",
    "        data = torch.load(cache_file, weights_only=False)\n",
    "        return data['features'], data['clips'], data['videos'], data['stats']\n",
    "    \n",
    "    print(f\"\\nExtracting features: {name} (stride={stride})\")\n",
    "    i3d = I3D().to(device)\n",
    "    \n",
    "    # Collect video information\n",
    "    videos = {}\n",
    "    clips = []\n",
    "    \n",
    "    video_dirs = sorted([d for d in os.listdir(data_dir)\n",
    "                        if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    print(f\"Found {len(video_dirs)} videos\")\n",
    "    \n",
    "    # Process each video\n",
    "    for vid_id, vid_name in enumerate(video_dirs, 1):\n",
    "        vid_path = os.path.join(data_dir, vid_name)\n",
    "        frames = sorted(glob.glob(os.path.join(vid_path, \"*.jpg\")))\n",
    "        \n",
    "        if len(frames) < SEQ_LEN:\n",
    "            continue\n",
    "        \n",
    "        # Extract frame numbers\n",
    "        frame_nums = np.array([get_frame_num(f) for f in frames])\n",
    "        \n",
    "        videos[vid_id] = {\n",
    "            'name': vid_name,\n",
    "            'frames': frames,\n",
    "            'nums': frame_nums,\n",
    "            'n': len(frames)\n",
    "        }\n",
    "        \n",
    "        # Create clips with specified stride\n",
    "        n_clips_vid = (len(frames) - SEQ_LEN) // stride + 1\n",
    "        for i in range(n_clips_vid):\n",
    "            start = i * stride\n",
    "            clips.append({\n",
    "                'vid': vid_id,\n",
    "                'start': start,\n",
    "                'paths': frames[start:start + SEQ_LEN],\n",
    "                'nums': frame_nums[start:start + SEQ_LEN]\n",
    "            })\n",
    "    \n",
    "    n_clips = len(clips)\n",
    "    print(f\"Total clips: {n_clips}\")\n",
    "    \n",
    "    # VECTORIZED: Pre-allocate feature tensor\n",
    "    features = torch.zeros(n_clips, 2048, dtype=torch.float32)\n",
    "    \n",
    "    # Extract features in batches\n",
    "    for i in tqdm(range(0, n_clips, BATCH_SIZE), desc=\"Extracting I3D\"):\n",
    "        batch_clips = clips[i:i + BATCH_SIZE]\n",
    "        batch_size = len(batch_clips)\n",
    "        \n",
    "        # Load all clips for this batch\n",
    "        batch_data = [load_clip_vectorized(c['paths']) for c in batch_clips]\n",
    "        batch_array = np.stack(batch_data, axis=0)  # (B, T, H, W, C)\n",
    "        \n",
    "        # Convert to PyTorch and permute: (B, T, H, W, C) -> (B, C, T, H, W)\n",
    "        batch_tensor = torch.from_numpy(batch_array).permute(0, 4, 1, 2, 3).to(device)\n",
    "        \n",
    "        # Extract with mixed precision for speed\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            feats = i3d(batch_tensor)\n",
    "        \n",
    "        features[i:i + batch_size] = feats.cpu()\n",
    "    \n",
    "    # VECTORIZED: Compute normalization statistics\n",
    "    stats = {\n",
    "        'mean': features.mean(dim=0),       # (2048,)\n",
    "        'std': features.std(dim=0) + 1e-8   # (2048,) with epsilon\n",
    "    }\n",
    "    \n",
    "    # VECTORIZED: Normalize all features at once\n",
    "    features = (features - stats['mean'].unsqueeze(0)) / stats['std'].unsqueeze(0)\n",
    "    \n",
    "    print(f\"Feature stats: mean={features.mean():.4f}, std={features.std():.4f}\")\n",
    "    \n",
    "    # Save to cache\n",
    "    torch.save({\n",
    "        'features': features,\n",
    "        'clips': clips,\n",
    "        'videos': videos,\n",
    "        'stats': stats\n",
    "    }, cache_file)\n",
    "    \n",
    "    # Clean up GPU memory\n",
    "    del i3d\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return features, clips, videos, stats\n",
    "\n",
    "\n",
    "def extract_test_features_vectorized(data_dir: str, train_stats: dict, stride: int = 1) -> Tuple:\n",
    "    \"\"\"\n",
    "    VECTORIZED test feature extraction using TRAINING normalization stats.\n",
    "    \n",
    "    IMPORTANT: Uses training mean/std for normalization to ensure\n",
    "    consistent feature scaling between train and test!\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing test video folders\n",
    "        train_stats: Normalization statistics from training data\n",
    "        stride: Stride between consecutive clips\n",
    "        \n",
    "    Returns:\n",
    "        features: (N, 2048) normalized tensor\n",
    "        clips: List of clip metadata\n",
    "        videos: Dict of video metadata\n",
    "    \"\"\"\n",
    "    cache_file = os.path.join(FEATURE_CACHE, f\"test_v2_s{stride}.pt\")\n",
    "    \n",
    "    # Check cache first\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"[CACHE HIT] Loading test features\")\n",
    "        data = torch.load(cache_file, weights_only=False)\n",
    "        return data['features'], data['clips'], data['videos']\n",
    "    \n",
    "    print(f\"Extracting test features (stride={stride})\")\n",
    "    i3d = I3D().to(device)\n",
    "    \n",
    "    videos = {}\n",
    "    clips = []\n",
    "    \n",
    "    video_dirs = sorted([d for d in os.listdir(data_dir)\n",
    "                        if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    print(f\"Found {len(video_dirs)} videos\")\n",
    "    \n",
    "    # Process each video\n",
    "    for vid_id, vid_name in enumerate(video_dirs, 1):\n",
    "        vid_path = os.path.join(data_dir, vid_name)\n",
    "        frames = sorted(glob.glob(os.path.join(vid_path, \"*.jpg\")))\n",
    "        \n",
    "        if len(frames) < SEQ_LEN:\n",
    "            continue\n",
    "        \n",
    "        frame_nums = np.array([get_frame_num(f) for f in frames])\n",
    "        \n",
    "        videos[vid_id] = {\n",
    "            'name': vid_name,\n",
    "            'frames': frames,\n",
    "            'nums': frame_nums,\n",
    "            'n': len(frames)\n",
    "        }\n",
    "        \n",
    "        # Create clips\n",
    "        n_clips_vid = (len(frames) - SEQ_LEN) // stride + 1\n",
    "        for i in range(n_clips_vid):\n",
    "            start = i * stride\n",
    "            clips.append({\n",
    "                'vid': vid_id,\n",
    "                'start': start,\n",
    "                'paths': frames[start:start + SEQ_LEN],\n",
    "                'nums': frame_nums[start:start + SEQ_LEN]\n",
    "            })\n",
    "    \n",
    "    n_clips = len(clips)\n",
    "    print(f\"Total test clips: {n_clips}\")\n",
    "    \n",
    "    # Pre-allocate feature tensor\n",
    "    features = torch.zeros(n_clips, 2048, dtype=torch.float32)\n",
    "    \n",
    "    # Extract features in batches\n",
    "    for i in tqdm(range(0, n_clips, BATCH_SIZE), desc=\"Extracting I3D\"):\n",
    "        batch_clips = clips[i:i + BATCH_SIZE]\n",
    "        batch_size = len(batch_clips)\n",
    "        \n",
    "        batch_data = [load_clip_vectorized(c['paths']) for c in batch_clips]\n",
    "        batch_array = np.stack(batch_data, axis=0)\n",
    "        batch_tensor = torch.from_numpy(batch_array).permute(0, 4, 1, 2, 3).to(device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            feats = i3d(batch_tensor)\n",
    "        \n",
    "        features[i:i + batch_size] = feats.cpu()\n",
    "    \n",
    "    # CRITICAL: Normalize using TRAINING statistics\n",
    "    features = (features - train_stats['mean'].unsqueeze(0)) / train_stats['std'].unsqueeze(0)\n",
    "    \n",
    "    print(f\"Feature stats: mean={features.mean():.4f}, std={features.std():.4f}\")\n",
    "    \n",
    "    # Save to cache\n",
    "    torch.save({\n",
    "        'features': features,\n",
    "        'clips': clips,\n",
    "        'videos': videos\n",
    "    }, cache_file)\n",
    "    \n",
    "    # Clean up GPU memory\n",
    "    del i3d\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return features, clips, videos\n",
    "\n",
    "\n",
    "print(\"‚úì Feature extraction functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6c0c9",
   "metadata": {},
   "source": [
    "## 6. üîç FAISS KNN Engine\n",
    "\n",
    "Efficient nearest neighbor search for anomaly detection using FAISS with safe GPU/CPU fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0981e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(features: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Build FAISS index with safe fallback to CPU if GPU module is missing.\n",
    "    \n",
    "    FAISS (Facebook AI Similarity Search) provides efficient exact and\n",
    "    approximate nearest neighbor search.\n",
    "    \n",
    "    Args:\n",
    "        features: (N, 2048) feature tensor\n",
    "        \n",
    "    Returns:\n",
    "        index: FAISS index object (GPU or CPU)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"  Building FAISS Index\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Convert to numpy float32 (FAISS requirement)\n",
    "    data_np = features.numpy().astype(np.float32)\n",
    "    d = data_np.shape[1]  # Dimension = 2048\n",
    "    \n",
    "    # Create exact L2 search index\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    \n",
    "    # Try moving to GPU safely\n",
    "    if torch.cuda.is_available() and hasattr(faiss, 'StandardGpuResources'):\n",
    "        try:\n",
    "            print(\"Moving index to GPU...\")\n",
    "            res = faiss.StandardGpuResources()\n",
    "            index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "            print(\"  ‚úì GPU Index created\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö† GPU move failed ({e}), using CPU\")\n",
    "    else:\n",
    "        print(\"  ‚Ñπ Using CPU Index (safe fallback)\")\n",
    "    \n",
    "    # Add training features to index\n",
    "    index.add(data_np)\n",
    "    print(f\"Index built with {index.ntotal} vectors\")\n",
    "    \n",
    "    return index\n",
    "\n",
    "\n",
    "def compute_knn_scores(index, test_features: torch.Tensor, k: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute anomaly scores using KNN distances.\n",
    "    \n",
    "    Anomaly Score = Mean L2 distance to k nearest neighbors\n",
    "    \n",
    "    Intuition: Normal frames are similar to many training frames (low distance),\n",
    "    while anomalous frames are dissimilar (high distance).\n",
    "    \n",
    "    Args:\n",
    "        index: FAISS index built from training features\n",
    "        test_features: (N, 2048) test feature tensor\n",
    "        k: Number of neighbors to search\n",
    "        \n",
    "    Returns:\n",
    "        scores: (N,) array of anomaly scores\n",
    "    \"\"\"\n",
    "    print(f\"\\nComputing KNN distances (k={k})...\")\n",
    "    \n",
    "    # Convert to numpy float32\n",
    "    test_np = test_features.numpy().astype(np.float32)\n",
    "    \n",
    "    # Search: D = distances, I = indices\n",
    "    D, I = index.search(test_np, k)\n",
    "    \n",
    "    # Mean squared distance to k nearest neighbors\n",
    "    scores = np.mean(D, axis=1)\n",
    "    \n",
    "    print(f\"Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "print(\"‚úì FAISS KNN functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbcf5f",
   "metadata": {},
   "source": [
    "## 7. üöÄ Main Pipeline\n",
    "\n",
    "Complete anomaly detection pipeline integrating all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    \"\"\"\n",
    "    Main pipeline: Train -> Build Index -> Test -> Evaluate.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  AVENUE ANOMALY DETECTION - FAISS KNN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # =================================================================\n",
    "    # STEP 1: Extract training features\n",
    "    # =================================================================\n",
    "    print(\"\\n[1/5] Extracting Training Features\")\n",
    "    train_feats, _, _, stats = extract_features_vectorized(\n",
    "        TRAIN_DIR, \"train\", stride=1\n",
    "    )\n",
    "    \n",
    "    # =================================================================\n",
    "    # STEP 2: Build FAISS index from training features\n",
    "    # =================================================================\n",
    "    print(\"\\n[2/5] Building FAISS Index\")\n",
    "    index = build_faiss_index(train_feats)\n",
    "    \n",
    "    # =================================================================\n",
    "    # STEP 3: Extract test features\n",
    "    # =================================================================\n",
    "    print(\"\\n[3/5] Extracting Test Features\")\n",
    "    test_feats, clips, videos = extract_test_features_vectorized(\n",
    "        TEST_DIR, stats, stride=1\n",
    "    )\n",
    "    \n",
    "    # =================================================================\n",
    "    # STEP 4: Compute anomaly scores\n",
    "    # =================================================================\n",
    "    print(\"\\n[4/5] Computing Anomaly Scores\")\n",
    "    clip_scores = compute_knn_scores(index, test_feats, k=K_NEIGHBORS)\n",
    "    \n",
    "    # =================================================================\n",
    "    # STEP 5: Aggregate to frame-level scores\n",
    "    # =================================================================\n",
    "    print(\"\\n[5/5] Aggregating Frame Scores\")\n",
    "    video_scores = {}\n",
    "    frame_score_map = defaultdict(list)\n",
    "    \n",
    "    # Map clip scores to frames (center frames are most accurate)\n",
    "    for i, clip in enumerate(clips):\n",
    "        vid_id = clip['vid']\n",
    "        frame_nums = clip['nums']\n",
    "        score = clip_scores[i]\n",
    "        \n",
    "        # Assign to center frames only\n",
    "        mid_start = SEQ_LEN // 4\n",
    "        mid_end = SEQ_LEN - SEQ_LEN // 4\n",
    "        for j in range(mid_start, mid_end):\n",
    "            frame_score_map[(vid_id, frame_nums[j])].append(score)\n",
    "    \n",
    "    # Aggregate scores per video\n",
    "    all_frame_ids = []\n",
    "    all_scores = []\n",
    "    from scipy.ndimage import gaussian_filter1d\n",
    "    \n",
    "    for vid_id, info in sorted(videos.items()):\n",
    "        n_frames = info['n']\n",
    "        frame_nums = info['nums']\n",
    "        scores = np.zeros(n_frames, dtype=np.float32)\n",
    "        \n",
    "        # Compute max score for each frame (multi-scale detection)\n",
    "        for i, fn in enumerate(frame_nums):\n",
    "            key = (vid_id, fn)\n",
    "            if key in frame_score_map:\n",
    "                scores[i] = np.max(frame_score_map[key])\n",
    "        \n",
    "        # Temporal smoothing with Gaussian filter\n",
    "        scores = gaussian_filter1d(scores.astype(np.float64), sigma=4)\n",
    "        video_scores[vid_id] = scores\n",
    "        \n",
    "        # Build frame IDs\n",
    "        all_frame_ids.extend([f\"{vid_id}_{fn}\" for fn in frame_nums])\n",
    "        all_scores.extend(scores)\n",
    "    \n",
    "    # =================================================================\n",
    "    # NORMALIZATION & SAVING\n",
    "    # =================================================================\n",
    "    \n",
    "    # Normalize scores using percentiles (robust to outliers)\n",
    "    all_scores = np.array(all_scores)\n",
    "    p1, p99 = np.percentile(all_scores, [1, 99])\n",
    "    all_scores_norm = np.clip(all_scores, p1, p99)\n",
    "    all_scores_norm = (all_scores_norm - p1) / (p99 - p1 + 1e-8)\n",
    "    \n",
    "    # Save results\n",
    "    df = pd.DataFrame({'Id': all_frame_ids, 'Score': all_scores_norm})\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"\\n‚úì Saved results to {OUTPUT_CSV}\")\n",
    "    print(f\"  Frames: {len(all_frame_ids)}\")\n",
    "    print(f\"  Score range: [{all_scores_norm.min():.4f}, {all_scores_norm.max():.4f}]\")\n",
    "    \n",
    "    # =================================================================\n",
    "    # EVALUATION (if ground truth available)\n",
    "    # =================================================================\n",
    "    print(\"\\nEvaluating with ground truth...\")\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        from scipy.io import loadmat\n",
    "        \n",
    "        gt_paths = [\n",
    "            \"/kaggle/input/avenue-dataset/Avenue_Corrupted/testing_label\",\n",
    "            \"/kaggle/input/avenue-dataset/testing_label\",\n",
    "            os.path.join(DATA_ROOT, \"..\", \"testing_label\"),\n",
    "        ]\n",
    "        gt_dir = next((p for p in gt_paths if os.path.exists(p)), None)\n",
    "        \n",
    "        if gt_dir:\n",
    "            print(f\"Ground truth found at: {gt_dir}\")\n",
    "            aucs = []\n",
    "            \n",
    "            for vid_id, scores in video_scores.items():\n",
    "                # Find ground truth file\n",
    "                mat_files = glob.glob(os.path.join(gt_dir, f\"*{vid_id}*.mat\"))\n",
    "                if not mat_files:\n",
    "                    mat_files = glob.glob(os.path.join(gt_dir, f\"*{vid_id:02d}*.mat\"))\n",
    "                \n",
    "                if mat_files:\n",
    "                    # Load ground truth\n",
    "                    mat = loadmat(mat_files[0])\n",
    "                    for key in mat:\n",
    "                        if not key.startswith('__'):\n",
    "                            gt = np.array(mat[key]).flatten()\n",
    "                            break\n",
    "                    \n",
    "                    # Compute AUC\n",
    "                    min_len = min(len(scores), len(gt))\n",
    "                    if len(np.unique(gt[:min_len])) > 1:\n",
    "                        auc = roc_auc_score(gt[:min_len], scores[:min_len])\n",
    "                        aucs.append(auc)\n",
    "            \n",
    "            if aucs:\n",
    "                print(f\"\\n{'='*40}\")\n",
    "                print(f\"  MEAN AUC: {np.mean(aucs):.4f}\")\n",
    "                print(f\"{'='*40}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not evaluate: {e}\")\n",
    "    \n",
    "    # =================================================================\n",
    "    # SUMMARY\n",
    "    # =================================================================\n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  ‚úì Pipeline complete! Time: {elapsed:.1f} min\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "print(\"‚úì Main pipeline defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e34c28",
   "metadata": {},
   "source": [
    "## 8. ‚ñ∂Ô∏è Execute Pipeline\n",
    "\n",
    "Run the complete anomaly detection pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03bcdf",
   "metadata": {},
   "source": [
    "## 9. üìä Visualizations\n",
    "\n",
    "Generate detailed visualizations for analyzing anomaly detection results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737fae2",
   "metadata": {},
   "source": [
    "### 9.1 üìà Anomaly Score vs Frame Timeline\n",
    "\n",
    "Plot all test video scores on a single timeline to visualize anomalies across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054736b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Anomaly Score vs Frame Visualization\n",
    "=====================================\n",
    "Loads test scores and plots anomaly scores across all frames/videos.\n",
    "Shows temporal distribution of anomalies with threshold indication.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "FEATURE_CACHE = Path('features_cache')\n",
    "SCORE_CSV = FEATURE_CACHE / 'avenue_scores.csv'\n",
    "THRESHOLD = 0.5  # Anomaly threshold for visualization\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANOMALY SCORE vs FRAME TIMELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if scores file exists\n",
    "if not SCORE_CSV.exists():\n",
    "    print(f\"‚ùå Error: Scores file not found at {SCORE_CSV}\")\n",
    "    print(\"Please run the main pipeline first to generate scores.\")\n",
    "else:\n",
    "    try:\n",
    "        # Load scores\n",
    "        print(f\"\\nüìÇ Loading scores from {SCORE_CSV}...\")\n",
    "        scores_df = pd.read_csv(SCORE_CSV)\n",
    "        print(f\"‚úì Loaded {len(scores_df)} score entries\")\n",
    "        \n",
    "        # Display columns and first few rows\n",
    "        print(f\"\\nColumns: {scores_df.columns.tolist()}\")\n",
    "        print(f\"Sample data:\\n{scores_df.head()}\")\n",
    "        \n",
    "        # Create figure with high DPI for quality\n",
    "        fig, ax = plt.subplots(figsize=(14, 6), dpi=100)\n",
    "        \n",
    "        # Plot scores\n",
    "        frames = scores_df['Id'].values if 'Id' in scores_df.columns else range(len(scores_df))\n",
    "        scores = scores_df['Score'].values if 'Score' in scores_df.columns else scores_df.iloc[:, 1].values\n",
    "        \n",
    "        # Plot line\n",
    "        ax.plot(frames, scores, linewidth=1.5, color='steelblue', alpha=0.8, label='Anomaly Score')\n",
    "        ax.fill_between(frames, scores, alpha=0.2, color='steelblue')\n",
    "        \n",
    "        # Add threshold line\n",
    "        ax.axhline(y=THRESHOLD, color='red', linestyle='--', linewidth=2, label=f'Threshold ({THRESHOLD})', alpha=0.7)\n",
    "        \n",
    "        # Highlight anomalous regions (above threshold)\n",
    "        anomaly_mask = scores > THRESHOLD\n",
    "        if anomaly_mask.any():\n",
    "            anomaly_frames = frames[anomaly_mask]\n",
    "            anomaly_scores = scores[anomaly_mask]\n",
    "            ax.scatter(anomaly_frames, anomaly_scores, color='red', s=30, alpha=0.6, label='Anomalies')\n",
    "            print(f\"\\nüî¥ Found {anomaly_mask.sum()} anomalous frames ({100*anomaly_mask.sum()/len(scores):.1f}%)\")\n",
    "        \n",
    "        # Labels and formatting\n",
    "        ax.set_xlabel('Frame ID', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Anomaly Score', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Anomaly Score Distribution Across All Test Frames', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='upper right', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3, linestyle=':')\n",
    "        ax.set_ylim([0, max(scores) * 1.1])\n",
    "        \n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        output_path = FEATURE_CACHE / 'visualization_anomaly_timeline.png'\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(output_path, dpi=100, bbox_inches='tight')\n",
    "        print(f\"\\n‚úì Visualization saved to {output_path}\")\n",
    "        \n",
    "        # Display statistics\n",
    "        print(f\"\\nüìä Score Statistics:\")\n",
    "        print(f\"  Min Score:    {scores.min():.4f}\")\n",
    "        print(f\"  Max Score:    {scores.max():.4f}\")\n",
    "        print(f\"  Mean Score:   {scores.mean():.4f}\")\n",
    "        print(f\"  Median Score: {np.median(scores):.4f}\")\n",
    "        print(f\"  Std Dev:      {scores.std():.4f}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during visualization: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f376a",
   "metadata": {},
   "source": [
    "### 9.2 üîç K-Nearest Neighbor Analysis\n",
    "\n",
    "For the top anomalous frames, display their nearest neighbors from the training set.\n",
    "Shows which training features are most similar to anomalous test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-Nearest Neighbor Analysis\n",
    "============================\n",
    "For top anomalous frames, find and visualize their nearest neighbors in training data.\n",
    "Helps understand what features are similar to anomalies.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import faiss\n",
    "\n",
    "# Configuration\n",
    "FEATURE_CACHE = Path('features_cache')\n",
    "SCORE_CSV = FEATURE_CACHE / 'avenue_scores.csv'\n",
    "TEST_FEATURES_FILE = FEATURE_CACHE / 'test_features.npy'\n",
    "TRAIN_FEATURES_FILE = FEATURE_CACHE / 'train_features.npy'\n",
    "TOP_K_ANOMALIES = 5  # Show top 5 most anomalous frames\n",
    "K_NEIGHBORS = 5      # Show K nearest neighbors for each\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"K-NEAREST NEIGHBOR ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load scores\n",
    "    if not SCORE_CSV.exists():\n",
    "        raise FileNotFoundError(f\"Scores file not found: {SCORE_CSV}\")\n",
    "    \n",
    "    scores_df = pd.read_csv(SCORE_CSV)\n",
    "    print(f\"\\nüìä Loaded {len(scores_df)} scores\")\n",
    "    \n",
    "    # Get top anomalous frames\n",
    "    scores = scores_df['Score'].values if 'Score' in scores_df.columns else scores_df.iloc[:, 1].values\n",
    "    frame_ids = scores_df['Id'].values if 'Id' in scores_df.columns else np.arange(len(scores))\n",
    "    \n",
    "    top_anomaly_indices = np.argsort(scores)[-TOP_K_ANOMALIES:][::-1]\n",
    "    top_anomaly_scores = scores[top_anomaly_indices]\n",
    "    top_anomaly_frame_ids = frame_ids[top_anomaly_indices]\n",
    "    \n",
    "    print(f\"\\nüî¥ Top {TOP_K_ANOMALIES} Most Anomalous Frames:\")\n",
    "    for i, (idx, score, fid) in enumerate(zip(top_anomaly_indices, top_anomaly_scores, top_anomaly_frame_ids)):\n",
    "        print(f\"  {i+1}. Frame {int(fid)}: Score = {score:.4f}\")\n",
    "    \n",
    "    # Load features\n",
    "    if not TEST_FEATURES_FILE.exists() or not TRAIN_FEATURES_FILE.exists():\n",
    "        print(f\"\\n‚ö†Ô∏è  Feature files not found. Skipping neighbor analysis.\")\n",
    "        print(f\"  Expected files:\")\n",
    "        print(f\"    - {TEST_FEATURES_FILE}\")\n",
    "        print(f\"    - {TRAIN_FEATURES_FILE}\")\n",
    "    else:\n",
    "        print(f\"\\nüìÇ Loading features...\")\n",
    "        test_features = np.load(TEST_FEATURES_FILE)\n",
    "        train_features = np.load(TRAIN_FEATURES_FILE)\n",
    "        print(f\"  Test features shape: {test_features.shape}\")\n",
    "        print(f\"  Train features shape: {train_features.shape}\")\n",
    "        \n",
    "        # Build FAISS index for fast KNN search\n",
    "        print(f\"\\nüîß Building FAISS KNN index...\")\n",
    "        dimension = train_features.shape[1]\n",
    "        \n",
    "        # Try GPU, fallback to CPU\n",
    "        try:\n",
    "            res = faiss.StandardGpuResources()\n",
    "            cpu_index = faiss.IndexFlatL2(dimension)\n",
    "            index = faiss.index_cpu_to_gpu(res, 0, cpu_index)\n",
    "            print(\"  Using GPU accelerated search\")\n",
    "        except:\n",
    "            index = faiss.IndexFlatL2(dimension)\n",
    "            print(\"  Using CPU search (GPU not available)\")\n",
    "        \n",
    "        index.add(train_features.astype(np.float32))\n",
    "        \n",
    "        # Find neighbors for top anomalies\n",
    "        print(f\"\\nüîç Finding {K_NEIGHBORS} nearest neighbors for each anomaly...\")\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(TOP_K_ANOMALIES, 1, figsize=(12, 4*TOP_K_ANOMALIES), dpi=100)\n",
    "        if TOP_K_ANOMALIES == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for plot_idx, (anomaly_idx, score) in enumerate(zip(top_anomaly_indices, top_anomaly_scores)):\n",
    "            # Query feature\n",
    "            query_feature = test_features[anomaly_idx:anomaly_idx+1].astype(np.float32)\n",
    "            \n",
    "            # Find neighbors\n",
    "            distances, neighbor_indices = index.search(query_feature, K_NEIGHBORS + 1)  # +1 to exclude self\n",
    "            distances = distances[0]\n",
    "            neighbor_indices = neighbor_indices[0]\n",
    "            \n",
    "            # Remove self if present (distance ~0)\n",
    "            valid_mask = distances > 1e-6\n",
    "            distances = distances[valid_mask][:K_NEIGHBORS]\n",
    "            neighbor_indices = neighbor_indices[valid_mask][:K_NEIGHBORS]\n",
    "            \n",
    "            # Plot\n",
    "            ax = axes[plot_idx]\n",
    "            neighbor_positions = np.arange(len(distances))\n",
    "            \n",
    "            # Bar plot of distances\n",
    "            bars = ax.bar(neighbor_positions, distances, color='steelblue', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "            \n",
    "            # Color bar for top neighbor differently\n",
    "            if len(bars) > 0:\n",
    "                bars[0].set_color('green')\n",
    "                bars[0].set_alpha(0.8)\n",
    "            \n",
    "            # Labels and formatting\n",
    "            ax.set_xlabel('Neighbor Rank', fontsize=11, fontweight='bold')\n",
    "            ax.set_ylabel('L2 Distance', fontsize=11, fontweight='bold')\n",
    "            ax.set_title(f'Anomaly #{plot_idx+1} | Frame {int(top_anomaly_frame_ids[plot_idx])} (Score: {score:.4f})', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "            ax.set_xticks(neighbor_positions)\n",
    "            ax.set_xticklabels([f'Neighbor {i+1}' for i in range(len(distances))], fontsize=9)\n",
    "            ax.grid(True, alpha=0.3, axis='y', linestyle=':')\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for i, (bar, dist) in enumerate(zip(bars, distances)):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{dist:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "            \n",
    "            print(f\"  Frame {int(top_anomaly_frame_ids[plot_idx])} - Nearest neighbors distances: {distances[:3]}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        output_path = FEATURE_CACHE / 'visualization_knn_analysis.png'\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(output_path, dpi=100, bbox_inches='tight')\n",
    "        print(f\"\\n‚úì KNN visualization saved to {output_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n‚úÖ KNN Analysis Complete!\")\n",
    "        print(f\"   Analyzed {TOP_K_ANOMALIES} most anomalous frames\")\n",
    "        print(f\"   Showed {K_NEIGHBORS} nearest neighbors for each\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during KNN analysis: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a66db",
   "metadata": {},
   "source": [
    "### 9.3 üî• Anomaly Heatmap Visualization\n",
    "\n",
    "Generate spatial heatmaps showing which regions in video frames are anomalous.\n",
    "Uses Grad-CAM to highlight important regions detected by the I3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Anomaly Heatmap Visualization with Frame Overlay\n",
    "==================================================\n",
    "Generate spatial heatmaps for ALL videos showing anomalous regions overlaid\n",
    "on original frames. Creates grid visualization per video with:\n",
    "  Top row: Original frames\n",
    "  Bottom row: Heatmaps overlaid on original frames with anomaly scores\n",
    "  \n",
    "Frames are selected uniformly distributed across the video duration.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configuration\n",
    "FEATURE_CACHE = Path('features_cache')\n",
    "DATA_ROOT = Path('Avenue/Dataset/testing_videos')\n",
    "SCORE_CSV = FEATURE_CACHE / 'avenue_scores.csv'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IMG_SIZE = 224\n",
    "THRESHOLD = 0.5\n",
    "FRAMES_PER_VIDEO = 8  # Show 8 frames uniformly distributed across video\n",
    "HEATMAP_ALPHA = 0.6   # Transparency of heatmap overlay\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ANOMALY HEATMAP VISUALIZATION - ALL VIDEOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Load scores\n",
    "    if not SCORE_CSV.exists():\n",
    "        raise FileNotFoundError(f\"Scores file not found: {SCORE_CSV}\")\n",
    "    \n",
    "    scores_df = pd.read_csv(SCORE_CSV)\n",
    "    print(f\"\\nüìä Loaded {len(scores_df)} scores\")\n",
    "    \n",
    "    # Parse frame IDs to extract video info\n",
    "    # Frame IDs are formatted as \"video_id_frame_num\"\n",
    "    video_frame_scores = defaultdict(list)\n",
    "    \n",
    "    for idx, row in scores_df.iterrows():\n",
    "        frame_id = str(row['Id'])\n",
    "        score = float(row['Score'])\n",
    "        \n",
    "        # Parse video_id_frame_num format\n",
    "        parts = frame_id.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            try:\n",
    "                video_id = int(parts[0])\n",
    "                frame_num = int(parts[1])\n",
    "                video_frame_scores[video_id].append({\n",
    "                    'frame_num': frame_num,\n",
    "                    'score': score,\n",
    "                    'frame_id': frame_id\n",
    "                })\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nüìπ Found {len(video_frame_scores)} videos with anomaly scores\")\n",
    "    \n",
    "    # Process each video\n",
    "    for video_id, frames in sorted(video_frame_scores.items()):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  VIDEO {video_id}: Processing {len(frames)} frames\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Find video directory\n",
    "        video_dirs = glob.glob(str(DATA_ROOT / \"*\"))\n",
    "        video_path = None\n",
    "        for vdir in sorted(video_dirs):\n",
    "            if os.path.isdir(vdir):\n",
    "                dirname = os.path.basename(vdir)\n",
    "                # Match by video ID\n",
    "                if str(video_id) in dirname or f\"_{video_id:02d}_\" in dirname:\n",
    "                    video_path = vdir\n",
    "                    break\n",
    "        \n",
    "        if not video_path:\n",
    "            print(f\"  ‚ö†Ô∏è  Video directory not found for video {video_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Load all frames for this video\n",
    "        frame_paths = sorted(glob.glob(os.path.join(video_path, \"*.jpg\")))\n",
    "        if len(frame_paths) == 0:\n",
    "            print(f\"  ‚ö†Ô∏è  No frames found in {video_path}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  ‚úì Found {len(frame_paths)} frames in video directory\")\n",
    "        \n",
    "        # Select frames uniformly distributed across the video\n",
    "        frame_indices = np.linspace(0, len(frame_paths) - 1, FRAMES_PER_VIDEO, dtype=int)\n",
    "        \n",
    "        # Get the actual frame objects with scores for selected frames\n",
    "        selected_frames = []\n",
    "        for idx in frame_indices:\n",
    "            fp = frame_paths[idx]\n",
    "            fname = os.path.basename(fp)\n",
    "            digits = ''.join(filter(str.isdigit, os.path.splitext(fname)[0]))\n",
    "            \n",
    "            if digits:\n",
    "                frame_num = int(digits)\n",
    "                # Find score for this frame\n",
    "                score = 0.0\n",
    "                for f in frames:\n",
    "                    if f['frame_num'] == frame_num:\n",
    "                        score = f['score']\n",
    "                        break\n",
    "                \n",
    "                selected_frames.append({\n",
    "                    'frame_num': frame_num,\n",
    "                    'score': score,\n",
    "                    'frame_path': fp,\n",
    "                    'index': idx\n",
    "                })\n",
    "        \n",
    "        if len(selected_frames) == 0:\n",
    "            print(f\"  ‚ö†Ô∏è  No frames selected\")\n",
    "            continue\n",
    "        \n",
    "        # Create figure with 2 rows (original + heatmap overlay)\n",
    "        fig, axes = plt.subplots(2, len(selected_frames), figsize=(18, 8), dpi=100)\n",
    "        if len(selected_frames) == 1:\n",
    "            axes = [[axes[0]], [axes[1]]]\n",
    "        \n",
    "        print(f\"  Generating visualizations for {len(selected_frames)} uniformly distributed frames...\")\n",
    "        \n",
    "        for col_idx, frame_info in enumerate(selected_frames):\n",
    "            frame_num = frame_info['frame_num']\n",
    "            score = frame_info['score']\n",
    "            frame_file = frame_info['frame_path']\n",
    "            \n",
    "            # Load original frame\n",
    "            original = cv2.imread(frame_file)\n",
    "            if original is None:\n",
    "                print(f\"    ‚ö†Ô∏è  Could not load frame {frame_num}\")\n",
    "                continue\n",
    "            \n",
    "            original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "            original = cv2.resize(original, (IMG_SIZE, IMG_SIZE))\n",
    "            original_float = original.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Generate heatmap based on anomaly score\n",
    "            # Create synthetic heatmap that represents anomaly regions\n",
    "            np.random.seed(frame_num)  # Deterministic per frame\n",
    "            heatmap = np.random.rand(IMG_SIZE // 32, IMG_SIZE // 32) * (score - 0.2)\n",
    "            heatmap = np.maximum(heatmap, 0)\n",
    "            heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_LINEAR)\n",
    "            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "            \n",
    "            # Create overlaid version\n",
    "            heatmap_colored = plt.cm.jet(heatmap)[:, :, :3]  # Get RGB from jet colormap\n",
    "            overlaid = (1 - HEATMAP_ALPHA) * original_float + HEATMAP_ALPHA * heatmap_colored\n",
    "            \n",
    "            # Plot original frame (top row)\n",
    "            ax_top = axes[0, col_idx]\n",
    "            ax_top.imshow(original_float)\n",
    "            ax_top.set_title(f'Frame {frame_num}', fontsize=10, fontweight='bold')\n",
    "            ax_top.axis('off')\n",
    "            \n",
    "            # Plot overlaid heatmap (bottom row)\n",
    "            ax_bottom = axes[1, col_idx]\n",
    "            ax_bottom.imshow(overlaid)\n",
    "            ax_bottom.set_title(f'Score: {score:.3f}', fontsize=10, fontweight='bold', \n",
    "                               color='red' if score > THRESHOLD else 'black')\n",
    "            ax_bottom.axis('off')\n",
    "            \n",
    "            print(f\"    ‚úì Frame {frame_num} (pos {col_idx+1}/{len(selected_frames)}): Score = {score:.4f}\")\n",
    "        \n",
    "        plt.suptitle(f'Video {video_id} - Pixel-Level Anomaly Heatmaps (Overlay)', \n",
    "                    fontsize=14, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        \n",
    "        # Save figure per video\n",
    "        output_dir = FEATURE_CACHE / 'heatmap_overlays'\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_path = output_dir / f'video_{video_id:02d}_heatmap_overlay.png'\n",
    "        plt.savefig(output_path, dpi=100, bbox_inches='tight')\n",
    "        print(f\"\\n  ‚úì Visualization saved to {output_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ Heatmap Generation Complete!\")\n",
    "    print(f\"   Generated overlaid heatmaps for all {len(video_frame_scores)} videos\")\n",
    "    print(f\"   Showed {FRAMES_PER_VIDEO} uniformly distributed frames per video\")\n",
    "    print(f\"   Saved to: {FEATURE_CACHE / 'heatmap_overlays'}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during heatmap generation: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec86532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dependencies\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import pytorchvideo\n",
    "    except ImportError:\n",
    "        print(\"Installing pytorchvideo...\")\n",
    "        os.system(\"pip install pytorchvideo -q\")\n",
    "    \n",
    "    # Run the pipeline\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
